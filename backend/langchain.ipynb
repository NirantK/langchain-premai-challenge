{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, there are many recipes that include chicken and rice. Here are a few examples:\n",
      "\n",
      "1. Chicken with Crispy Rice: This is a simple dish that combines fried chicken strips with crispy rice for a satisfying and crunchy meal.\n",
      "2. Easy Fried Rice with Chicken and Broccolini: This recipe uses leftover chicken to make a quick and easy fried rice dish, which is then paired with broccolini (a type of broccoli) for added flavor and nutrition.\n",
      "3. Hainanese Chicken Rice: This classic Southeast Asian dish involves poaching chicken in a fragrant broth before serving it over a bed of steamed rice.\n",
      "4. Latin-Style Chicken and Rice: This recipe combines grilled chicken with rice, beans, and various Latin American spices for a flavorful and hearty meal.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import Qdrant\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"random-string\"\n",
    "\n",
    "\n",
    "# Using sentence transformers all-MiniLM-L6-v2\n",
    "embeddings = OpenAIEmbeddings(openai_api_base=\"http://localhost:8444/v1\")\n",
    "\n",
    "# Qdrant client\n",
    "client = QdrantClient(\"localhost\", port=6333)\n",
    "qdrant_docsearch = Qdrant(client=client, collection_name=\"recipe_title_collection\", embeddings=embeddings, content_payload_key=\"title\")\n",
    "\n",
    "# chat completion llm\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_base=\"http://localhost:8111/v1\", temperature=0.2, max_tokens=256\n",
    ")\n",
    "\n",
    "# Using OpenAI directly\n",
    "# qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=qdrant_docsearch.as_retriever())\n",
    "\n",
    "# Using Vicuna via Premai app \n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=qdrant_docsearch.as_retriever(), return_source_documents=True)\n",
    "\n",
    "query = \"Any recipe with chicken and rice?\"\n",
    "result = qa.run(query)\n",
    "\n",
    "print(result)\n",
    "\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# qa = ConversationalRetrievalChain.from_llm(\n",
    "#     ChatOpenAI(temperature=0, openai_api_base=\"http://localhost:8111/v1\"),\n",
    "#     qdrant_docsearch.as_retriever(),\n",
    "#     condense_question_llm = ChatOpenAI(temperature=0, openai_api_base=\"http://localhost:8111/v1\"),\n",
    "# )\n",
    "\n",
    "# chat_history = []\n",
    "# query = \"Any recipe with chicken and rice?\"\n",
    "# result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' A large language model is a type of artificial intelligence (AI) that has been trained on a vast amount of text data. It can process and generate human-like language, making it useful for tasks such as natural language processing, machine translation, and language generation.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"random-string\"\n",
    "\n",
    "chat = ChatOpenAI(openai_api_base=\"http://localhost:8111/v1\", max_tokens=128)\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"Can you explain what is a large language model?\")\n",
    "]\n",
    "chat(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aditya",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
