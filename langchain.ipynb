{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Yes, there are four recipes that include chicken and rice: Chicken with Crispy Rice, Easy Fried Rice with Chicken and Broccolini, Hainanese Chicken Rice, and Latin-Style Chicken and Rice.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import Qdrant\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"random-string\"\n",
    "\n",
    "\n",
    "# Using sentence transformers all-MiniLM-L6-v2\n",
    "embeddings = OpenAIEmbeddings(openai_api_base=\"http://localhost:8444/v1\")\n",
    "\n",
    "# Qdrant client\n",
    "client = QdrantClient(\"localhost\", port=6333)\n",
    "qdrant_docsearch = Qdrant(client=client, collection_name=\"recipe_title_collection\", embeddings=embeddings, content_payload_key=\"title\")\n",
    "\n",
    "# Using OpenAI directly\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=qdrant_docsearch.as_retriever())\n",
    "\n",
    "# Using Vicuna via Premai app \n",
    "# qa = RetrievalQA.from_chain_type(llm=OpenAI(openai_api_base=\"http://localhost:8111/v1\"), chain_type=\"stuff\", retriever=qdrant_docsearch.as_retriever())\n",
    "\n",
    "query = \"Any recipe with chicken and rice?\"\n",
    "result = qa.run(query)\n",
    "\n",
    "print(result)\n",
    "\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# qa = ConversationalRetrievalChain.from_llm(\n",
    "#     ChatOpenAI(temperature=0, openai_api_base=\"http://localhost:8111/v1\"),\n",
    "#     qdrant_docsearch.as_retriever(),\n",
    "#     condense_question_llm = ChatOpenAI(temperature=0, openai_api_base=\"http://localhost:8111/v1\"),\n",
    "# )\n",
    "\n",
    "# chat_history = []\n",
    "# query = \"Any recipe with chicken and rice?\"\n",
    "# result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' Sure! A large language model is a type of artificial intelligence (AI) that is trained on a vast amount of text data to generate human-like text. It uses deep learning algorithms to learn patterns and relationships in the input data, which it can then use to predict what comes next or generate new text in response to a prompt.\\n\\nThere are many different large language models out there, but they all share the same basic architecture: a series of interconnected nodes that process input and output text. Some of the most well-known large language models include GPT-3, BERT, and RoBERTa.\\n\\n', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"random-string\"\n",
    "\n",
    "chat = ChatOpenAI(openai_api_base=\"http://localhost:8111/v1\", max_tokens=128)\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"Can you explain what is a large language model?\")\n",
    "]\n",
    "chat(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aditya",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
